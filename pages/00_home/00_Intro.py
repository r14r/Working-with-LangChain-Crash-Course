import streamlit as st

st.set_page_config(
    page_title="LangChain & Ollama Workshop",
    page_icon="ğŸš€"
)

st.header('ğŸš€ LangChain mit Ollama: Fortgeschrittener Workshop')

st.subheader('Lokale KI-Anwendungen entwickeln - Praktisch und hands-on!')

st.write('''
Willkommen zu diesem fortgeschrittenen Workshop Ã¼ber LangChain mit Ollama! Hier lernst du,
wie du leistungsstarke KI-Anwendungen entwickelst, die vollstÃ¤ndig lokal auf deinem System 
laufen - ohne Cloud-AbhÃ¤ngigkeiten, ohne API-Kosten, mit voller Datenkontrolle.

LangChain ist ein mÃ¤chtiges Framework fÃ¼r die Entwicklung von Large Language Model (LLM) 
Anwendungen. Es bietet Abstraktionen und Werkzeuge, die das Arbeiten mit verschiedenen 
LLMs, Vektorspeichern, Dokumenten und APIs erheblich vereinfachen.
''')

st.subheader('ğŸ¯ Was du lernen wirst')

col1, col2 = st.columns(2)

with col1:
    st.write('''
    **Kernkonzepte:**
    - ğŸ¤– LLM-Integration (Ollama)
    - ğŸ“ Prompt Engineering & Templates
    - â›“ï¸ Chain-Patterns (LCEL)
    - ğŸ§  Memory-Management
    ''')

with col2:
    st.write('''
    **Fortgeschrittene Themen:**
    - ğŸ“Š Embeddings & Vektorspeicher
    - ğŸ“„ Document Processing
    - ğŸ” RAG-Implementierungen
    - ğŸ› ï¸ Praktische Projekte
    ''')

st.info('ğŸ’¡ Dieser Workshop nutzt ausschlieÃŸlich **Ollama** fÃ¼r lokale LLM-Inferenz - keine OpenAI API Keys erforderlich!', icon="ğŸ’¡")

st.subheader('ğŸ“ Voraussetzungen')

st.write('''
Um das Beste aus diesem Workshop herauszuholen, solltest du mitbringen:

- **Python-Grundkenntnisse**: Du solltest mit Python-Syntax, Funktionen und Klassen vertraut sein
- **Ollama-Installation**: Stelle sicher, dass Ollama auf deinem System installiert ist
- **Grundlegendes VerstÃ¤ndnis von LLMs**: Was sind Large Language Models und wie funktionieren sie?

**Neu in Python?** Hier sind hilfreiche Ressourcen:
- [Python Tutorial Deutsch](https://www.python-kurs.eu/)
- [Python lernen - freeCodeCamp](https://www.freecodecamp.org/news/learn-python-free-python-courses-for-beginners/)
''')

st.subheader('ğŸ’» Verwendete Technologien')

st.write('''
In diesem Workshop arbeiten wir mit modernen, Open-Source-Technologien:

- **[LangChain](https://www.langchain.com/)** - Das fÃ¼hrende Framework fÃ¼r LLM-Anwendungen (Python)
- **[Ollama](https://ollama.com/)** - Lokale LLM-Inferenz (Llama, Mistral, Gemma, etc.)
- **[Streamlit](https://streamlit.io/)** - Schnelle Web-UI-Entwicklung fÃ¼r Data Science & KI
- **[LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/)** - Moderne Chain-Komposition

Alle verwendeten Tools sind Open Source und kÃ¶nnen kostenlos genutzt werden.
''')

